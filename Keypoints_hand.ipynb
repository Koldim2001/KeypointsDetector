{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основные точки руки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands модель - множество рук\n",
    "Данная модель позволяет находить множество рук но не различает правую и левую руки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python mediapipe msvc-runtime\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/hand_landmarks.png\" alt=\"точки тела\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение поднят большой палец вверх или опущен вниз для всех имеющихся рук на видео:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Инициализация Mediapipe Hands\n",
    "hands = mp_hands.Hands(max_num_hands=3, min_detection_confidence=0.75,\n",
    "                           min_tracking_confidence=0.5,)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Перевод кадра в RGB\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Обнаружение рук на кадре\n",
    "    results = hands.process(rgb_image)\n",
    "\n",
    "    # Отрисовка результатов на кадре\n",
    "    if results.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Отрисовка точек руки\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Позиция большого пальца (4-й элемент) правой руки\n",
    "            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "            thumb_tip_x, thumb_tip_y = int(thumb_tip.x * image.shape[1]), int(thumb_tip.y * image.shape[0])\n",
    "\n",
    "            # Позиция всех кончиков пальцев руки кроме - большого\n",
    "            fingertips = [hand_landmarks.landmark[i] for i in [8,12,16,20]]  \n",
    "            fingertips_x = [int(point.x * image.shape[1]) for point in fingertips]\n",
    "            fingertips_y = [int(point.y * image.shape[0]) for point in fingertips]\n",
    "\n",
    "            # Поднят ли большой палец (он выше всех других и оттапырен > 0.85 ширины оствльных пальцев) \n",
    "            # последнее условие для отработки случаев когда палец вытянут а рука боком\n",
    "            if (thumb_tip_y < min(fingertips_y) and \n",
    "                        abs(min(fingertips_y)-thumb_tip_y) > 0.85* (max(fingertips_y)-min(fingertips_y))\n",
    "                        and abs((fingertips_x[2])-thumb_tip_x) < 0.85* (max(fingertips_y)-min(fingertips_y))):            \n",
    "                class_symbol = ':)'\n",
    "            # Поднят ли большой палец (он ниже всех других и оттапырен > 0.85 ширины оствльных пальцев)\n",
    "            elif (thumb_tip_y > max(fingertips_y) and \n",
    "                        abs(max(fingertips_y)-thumb_tip_y) > 0.85*(max(fingertips_y)-min(fingertips_y))\n",
    "                        and abs((fingertips_x[2])-thumb_tip_x) < 1.75* (max(fingertips_y)-min(fingertips_y))):\n",
    "                class_symbol = ':('\n",
    "            else:\n",
    "                class_symbol = ':|'\n",
    "\n",
    "            # Отрисовка символа класса\n",
    "            cv2.putText(image, class_symbol, (50, (i*70) + 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Отображение кадра\n",
    "    cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "    # Выход из цикла по нажатию клавиши 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holistic модель - различаем правую и левую\n",
    "Оценим результат эмоции лишь по правой руке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "\tmin_detection_confidence=0.5,\n",
    "\tmin_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "drawing_spec_lines_r = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(255,0,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "drawing_spec_lines_l = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(0,255,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    " \n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    " \n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    " \n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    " \n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "   \n",
    "    # Drawing Right hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.right_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_r\n",
    "    )\n",
    " \n",
    "    # Drawing Left hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.left_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_l\n",
    "    )\n",
    "  \n",
    "    if results.right_hand_landmarks:\n",
    "      # Позиция большого пальца (4-й элемент) правой руки\n",
    "      thumb_tip = results.right_hand_landmarks.landmark[4]\n",
    "      thumb_tip_x, thumb_tip_y = int(thumb_tip.x * image.shape[1]), int(thumb_tip.y * image.shape[0])\n",
    "\n",
    "      # Позиция всех кончиков пальцев руки кроме - большого\n",
    "      fingertips = [results.right_hand_landmarks.landmark[i] for i in [8,12,16,20]]  \n",
    "      fingertips_x = [int(point.x * image.shape[1]) for point in fingertips]\n",
    "      fingertips_y = [int(point.y * image.shape[0]) for point in fingertips]\n",
    "\n",
    "      # Поднят ли большой палец (он выше всех других и оттапырен > 0.85 ширины оствльных пальцев) \n",
    "      # последнее условие для отработки случаев когда палец вытянут а рука боком\n",
    "      if (thumb_tip_y < min(fingertips_y) and \n",
    "                  abs(min(fingertips_y)-thumb_tip_y) > 0.85* (max(fingertips_y)-min(fingertips_y))\n",
    "                  and abs((fingertips_x[2])-thumb_tip_x) < 0.85* (max(fingertips_y)-min(fingertips_y))):            \n",
    "          class_symbol = ':)'\n",
    "      # Поднят ли большой палец (он ниже всех других и оттапырен > 0.85 ширины оствльных пальцев)\n",
    "      elif (thumb_tip_y > max(fingertips_y) and \n",
    "                  abs(max(fingertips_y)-thumb_tip_y) > 0.85*(max(fingertips_y)-min(fingertips_y))\n",
    "                  and abs((fingertips_x[2])-thumb_tip_x) < 1.75* (max(fingertips_y)-min(fingertips_y))):\n",
    "          class_symbol = ':('\n",
    "      else:\n",
    "          class_symbol = ''\n",
    "\n",
    "      # Отрисовка символа класса\n",
    "      cv2.putText(image, class_symbol, (50, (i*70) + 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    " \n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holistic модель - сразу все находим (руки, тело и лицо)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_fps(current_fps, fps_buffer):\n",
    "    # Добавляем текущее значение в буфер\n",
    "    fps_buffer.pop(0)\n",
    "    fps_buffer.append(current_fps)\n",
    "\n",
    "    # Вычисляем среднее значение в буфере\n",
    "    average_fps = sum(fps_buffer) / len(fps_buffer)\n",
    "\n",
    "    return average_fps, fps_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "\tmin_detection_confidence=0.75,\n",
    "\tmin_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec_lines_r = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(255,0,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "drawing_spec_lines_l = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(0,255,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    " \n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "N = 15 # окно усреднения fps\n",
    "fps_buffer = [0] * N  # Инициализация массива предыдущих значений\n",
    " \n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    " \n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    " \n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "    # Drawing the Facial Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.face_landmarks,\n",
    "      mp_holistic.FACEMESH_CONTOURS,\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(255,0,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      ),\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(0,255,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      )\n",
    "    )\n",
    " \n",
    "    # Drawing Right hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.right_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_r\n",
    "    )\n",
    " \n",
    "    # Drawing Left hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.left_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_l\n",
    "    )\n",
    "\n",
    "    # Drawing pose Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.pose_landmarks, \n",
    "      mp_holistic.POSE_CONNECTIONS\n",
    "    )\n",
    "\n",
    "     \n",
    "    # Calculating the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "\n",
    "    fps, fps_buffer = calculate_average_fps(fps, fps_buffer)\n",
    "     \n",
    "    # Displaying FPS on the image\n",
    "    cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (255,100,0), 2)\n",
    " \n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    " \n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
